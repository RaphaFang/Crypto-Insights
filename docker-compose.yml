services:

  kafka:
    image: bitnami/kafka:4.0.0
    ports:
      - "9092:9092"
    environment:
      KAFKA_CFG_NODE_ID: "0"
      KAFKA_CFG_PROCESS_ROLES: "broker,controller"
      KAFKA_OPTS: "-Duser.timezone=Europe/Copenhagen"
      KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: "0@localhost:9093"
      KAFKA_CFG_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_CFG_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,CONTROLLER://kafka:9093
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_CFG_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_CFG_KRAFT_STORAGE_ROOT_DIR: /bitnami/kafka/data
      ALLOW_PLAINTEXT_LISTENER: "yes"
      KAFKA_CFG_LOG_RETENTION_MINUTES: "5"
      KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE: "true"
      # 這行之後要修正，因為只會有一主題，一分區，接下來要調整成寫定。但是需要在多一個docker service去完成
    volumes:
      - ./kafka_dir/data:/bitnami/kafka/data
    healthcheck:
      test: ["CMD", "/opt/bitnami/kafka/bin/kafka-broker-api-versions.sh", "--bootstrap-server", "localhost:9092"]
      start_period: 15s
      interval: 3s
      timeout: 3s
      retries: 5
    networks: [k_f_net]

  ws_to_kafka_connector:
    build:
      context: .
      dockerfile: kafka_ws_connector_dir/Dockerfile
    environment:
      WS_URL: "wss://stream.binance.com:9443/ws/btcusdt@trade"
      KAFKA_BOOTSTRAP: "kafka:9092"
      KAFKA_TOPIC: "btc_raw"
      LOG_LEVEL: "info"
      TZ: "Europe/Copenhagen"
    depends_on:
      kafka:
        condition: service_healthy
    restart: unless-stopped
    networks: [k_f_net]

  jm:
    image: flink:1.20.2-scala_2.12-java17
    command: standalone-job -c com.example.KafkaReadOnly /opt/flink/usrlib/flink-job-1.0.0.jar
    ports:
      - "8081:8081"
    environment:
      - |
        FLINK_PROPERTIES=
          jobmanager.rpc.address: jm
          state.checkpoints.dir: file:///opt/flink/checkpoints
    # 這邊的 jm container name 建議小寫，因為大寫會轉回小寫，但是我要DNS連接，這時候我想連大寫的找不到
    volumes:
      - ./flink_dir/checkpoints:/opt/flink/checkpoints
      - ./flink_dir/usrlib:/opt/flink/usrlib          
    networks: [k_f_net]

  tm:
    image: flink:1.20.2-scala_2.12-java17
    command: taskmanager
    environment:
      - |
        FLINK_PROPERTIES=
          jobmanager.rpc.address: jm
          taskmanager.numberOfTaskSlots: 4
          state.checkpoints.dir: file:///opt/flink/checkpoints
    volumes:
      - ./flink_dir/checkpoints:/opt/flink/checkpoints
      - ./flink_dir/usrlib:/opt/flink/usrlib          
    networks: [k_f_net]
  
  clickhouse:
    image: clickhouse/clickhouse-server:25.8.2.29
    environment:
      TZ: "Europe/Copenhagen"
      CLICKHOUSE_USER: test
      CLICKHOUSE_PASSWORD: "test"
      CLICKHOUSE_DB: agg
      CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT: "1"
    ports:
      - "8123:8123"
      - "9000:9000" 
    volumes:
      - ./clickhouse_dir/ch_data:/var/lib/clickhouse
      - ./clickhouse_dir/ch_logs:/var/log/clickhouse-server
    # ulimits, cap_add are setup for better performance
    ulimits:
      nofile: { soft: 262144, hard: 262144 }
    cap_add:
      - IPC_LOCK
      - SYS_NICE  
    healthcheck:
      test: ["CMD", "clickhouse-client", "-h", "localhost", "--query", "SELECT 1"]
      interval: 1s
      timeout: 1s
      retries: 5
      start_period: 3s
    networks: [k_f_net]

  # init-clickhouse:
  # # 這在調整好後，就可以砍掉了，沒必要每次都重新來。
  #   image: clickhouse/clickhouse-server:25.8.2.29
  #   depends_on:
  #     clickhouse:
  #       condition: service_healthy
  #   entrypoint: ["/bin/sh","-lc"]
  #   command: >
  #     'clickhouse-client -h clickhouse -u test --password "test" --multiquery < /sql/init.sql &&
  #     echo "msg from: container init-clickhouse, init done"'
  #   # 一定要加上''，不然這邊shell會讀成段落段落，不是一條完整指令
  #   volumes:
  #     - ./clickhouse_dir/connector:/sql
  #   restart: "no"
  #   networks: [k_f_net]

  grafana:
    image: grafana/grafana:12.1.1
    ports:
      - "3000:3000"
    environment:
    - GF_INSTALL_PLUGINS=vertamedia-clickhouse-datasource
    volumes:
      - ./grafana_dir/grafana-data:/var/lib/grafana
    networks: [k_f_net]

networks:
  k_f_net: {}